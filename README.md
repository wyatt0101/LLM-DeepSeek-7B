# ğŸ’¬ DeepSeek-7B Local Deployment and Usage Examples

This project is based on Self-LLM and includes features such as model downloading, FastAPI deployment, LangChain integration, Streamlit Web Chatbot, as well as LoRA fine-tuning training and inference.

---

## Features
- `download.py`: Automatically downloads model files.
- `api.py`: FastAPI service providing HTTP access.
- `test.py`: LangChain local model example.
- `chatBot.py`: Streamlit web chat interface.
- `DeepSeek_Lora.py`: Model fine-tuning training script.
- `DeepSeek_Lora_test.py`: Loads fine-tuned weights and performs inference.

  
## Installation & Usage
Clone the project:

```bash
git clone https://github.com/wyatt0101/LLM-DeepSeek-7B.git
cd LLM-DeepSeek-7B
```

Install required packages:
```
pip install -r requirements.txt
```

Download model files:
ModelScope downloads the specified model files to the local cache directory.
```
python download.py
```

### FastAPI Deployment
Deploy a local HTTP API with FastAPI that listens on port 6006. It supports receiving JSON requests and returns text generated by the local model.

- Loads local model and tokenizer
- Receives user prompts and max generation length
- Returns generated model outputs
```
python api.py
```

### LangChain Local Model Integration
Custom LangChain LLM class based on the local Self-LLM model, convenient for using the local large model within LangChain pipelines.
```
python test.py
```

### Streamlit Web Chatbot
An interactive chatbot interface built with Streamlit, supporting multi-turn conversations.
After starting, visit http://127.0.0.1:6006 to use the chat UI.
```
streamlit run ./chatBot.py --server.address 127.0.0.1 --server.port 6006
```

### Model Fine-tuning and Inference
Fine-tune the local pretrained model with LoRA using training data from `huanhuan.json` at the project root. The JSON file contains a list of instruction-input-output pairs. Fine-tuned weights are saved to `./output/DeepSeek_LoRA`.

```
python DeepSeek_Lora.py
```
Sample format of the fine-tuning data file `huanhuan.json`:
```
[
  {
    "instruction": "è¿™ä¸ªæ¸©å¤ªåŒ»å•Šï¼Œä¹Ÿæ˜¯å¤æ€ªï¼Œè°ä¸çŸ¥å¤ªåŒ»ä¸å¾—çš‡å‘½ä¸èƒ½ä¸ºçš‡æ—ä»¥å¤–çš„äººè¯·è„‰è¯Šç—…ï¼Œä»–å€’å¥½ï¼Œåå¤©åŠæœˆä¾¿å¾€å’±ä»¬åºœé‡Œè·‘ã€‚",
    "input": "",
    "output": "ä½ ä»¬ä¿©è¯å¤ªå¤šäº†ï¼Œæˆ‘è¯¥å’Œæ¸©å¤ªåŒ»è¦ä¸€å‰‚è¯ï¼Œå¥½å¥½æ²»æ²»ä½ ä»¬ã€‚"
  },
  ...
]
```

Inferenceï¼šLoad the pretrained model and the saved LoRA fine-tuned weights to generate text responses.
```
python DeepSeek_Lora_test.py
```

