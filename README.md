# DeepSeek LLM Project

This project is based on Self-LLM and includes features such as model downloading, FastAPI deployment, LangChain integration, Streamlit Web Chatbot, as well as LoRA fine-tuning training and inference.

---

## Features
- `download.py`: Automatically downloads model files.
- `api.py`: FastAPI service providing HTTP access.
- `test.py`: LangChain local model example.
- `chatBot.py`: Streamlit web chat interface.
- `DeepSeek_Lora.py`: Model fine-tuning training script.
- `DeepSeek_Lora_test.py`: Loads fine-tuned weights and performs inference.

  
## Installation & Usage
Clone the project:

```bash
git clone https://github.com/wyatt0101/LLM-DeepSeek-7B.git
cd LLM-DeepSeek-7B
```

Install required packages:
```
pip install -r requirements.txt
```

Download model files:
ModelScope downloads the specified model files to the local cache directory.
```
python download.py
```

### FastAPI Deployment
Deploy a local HTTP API with FastAPI that listens on port 6006. It supports receiving JSON requests and returns text generated by the local model.

- Loads local model and tokenizer
- Receives user prompts and max generation length
- Returns generated model outputs
```
python api.py
```

### LangChain Local Model Integration
Custom LangChain LLM class based on the local Self-LLM model, convenient for using the local large model within LangChain pipelines.
```
python test.py
```

### Streamlit Web Chatbot
An interactive chatbot interface built with Streamlit, supporting multi-turn conversations.
After starting, visit http://127.0.0.1:6006 to use the chat UI.
```
streamlit run ./chatBot.py --server.address 127.0.0.1 --server.port 6006
```

### Model Fine-tuning and Inference
Fine-tune the local pretrained model with LoRA using training data from `huanhuan.json` at the project root. The JSON file contains a list of instruction-input-output pairs. Fine-tuned weights are saved to `./output/DeepSeek_LoRA`.

```
python DeepSeek_Lora.py
```
Sample format of the fine-tuning data file `huanhuan.json`:
```
[
  {
    "instruction": "这个温太医啊，也是古怪，谁不知太医不得皇命不能为皇族以外的人请脉诊病，他倒好，十天半月便往咱们府里跑。",
    "input": "",
    "output": "你们俩话太多了，我该和温太医要一剂药，好好治治你们。"
  },
  ...
]
```

Inference：Load the pretrained model and the saved LoRA fine-tuned weights to generate text responses.
```
python DeepSeek_Lora_test.py
```

